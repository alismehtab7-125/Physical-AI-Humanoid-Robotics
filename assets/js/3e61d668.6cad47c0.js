"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[424],{818:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>r,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-04/high-level-task-planning","title":"High-Level Task Planning using LLMs","description":"Introduction to High-Level Task Planning","source":"@site/docs/module-04/18-high-level-task-planning.md","sourceDirName":"module-04","slug":"/module-04/high-level-task-planning","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-04/high-level-task-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/alismehtab7-125/Physical-AI-Humanoid-Robotics/edit/main/docs/module-04/18-high-level-task-planning.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"High-Level Task Planning using LLMs"},"sidebar":"tutorialSidebar","previous":{"title":"Humanoid Navigation in Complex Environments","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-04/navigating-complex-environments"},"next":{"title":"Real-World Deployment and Challenges","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-04/real-world-deployment"}}');var l=t(4848),o=t(8453);const i={sidebar_position:3,title:"High-Level Task Planning using LLMs"},s="High-Level Task Planning using LLMs",r={},c=[{value:"Introduction to High-Level Task Planning",id:"introduction-to-high-level-task-planning",level:2},{value:"The Task Planning Pipeline",id:"the-task-planning-pipeline",level:3},{value:"Planning Domain Definition Language (PDDL)",id:"planning-domain-definition-language-pddl",level:2},{value:"Overview of PDDL",id:"overview-of-pddl",level:3},{value:"PDDL Structure for Robotics",id:"pddl-structure-for-robotics",level:3},{value:"PDDL Planning with External Solvers",id:"pddl-planning-with-external-solvers",level:3},{value:"LLM-Guided Task Planning",id:"llm-guided-task-planning",level:2},{value:"Natural Language to PDDL Translation",id:"natural-language-to-pddl-translation",level:3},{value:"Hierarchical Task Networks (HTN)",id:"hierarchical-task-networks-htn",level:2},{value:"HTN vs PDDL",id:"htn-vs-pddl",level:3},{value:"Integration with ROS 2 Task Planning",id:"integration-with-ros-2-task-planning",level:2},{value:"Task Planning Node",id:"task-planning-node",level:3},{value:"LLM-Enhanced Planning Strategies",id:"llm-enhanced-planning-strategies",level:2},{value:"Context-Aware Planning",id:"context-aware-planning",level:3},{value:"Multi-Modal Planning",id:"multi-modal-planning",level:3},{value:"Handling Uncertainty and Failures",id:"handling-uncertainty-and-failures",level:2},{value:"Plan Monitoring and Recovery",id:"plan-monitoring-and-recovery",level:3},{value:"Performance Optimization and Best Practices",id:"performance-optimization-and-best-practices",level:2},{value:"1. Plan Caching",id:"1-plan-caching",level:3},{value:"2. Hierarchical Plan Execution",id:"2-hierarchical-plan-execution",level:3},{value:"Future Directions and Research",id:"future-directions-and-research",level:2},{value:"1. Learning from Execution",id:"1-learning-from-execution",level:3},{value:"2. Collaborative Planning",id:"2-collaborative-planning",level:3}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(e.header,{children:(0,l.jsx)(e.h1,{id:"high-level-task-planning-using-llms",children:"High-Level Task Planning using LLMs"})}),"\n",(0,l.jsx)(e.h2,{id:"introduction-to-high-level-task-planning",children:"Introduction to High-Level Task Planning"}),"\n",(0,l.jsx)(e.p,{children:"High-level task planning involves converting abstract human commands into executable robot actions. This process requires understanding natural language, reasoning about the environment, and decomposing complex tasks into primitive actions that the robot can execute. Large Language Models (LLMs) have revolutionized this field by providing sophisticated natural language understanding and reasoning capabilities."}),"\n",(0,l.jsx)(e.h3,{id:"the-task-planning-pipeline",children:"The Task Planning Pipeline"}),"\n",(0,l.jsx)(e.p,{children:"The high-level task planning process typically follows this pipeline:"}),"\n",(0,l.jsxs)(e.ol,{children:["\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Natural Language Understanding"}),": Interpret the human command"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Environment Context Integration"}),": Combine command with current world state"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Task Decomposition"}),": Break down the task into subtasks"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Action Sequencing"}),": Order actions logically"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Execution Monitoring"}),": Track progress and handle failures"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"planning-domain-definition-language-pddl",children:"Planning Domain Definition Language (PDDL)"}),"\n",(0,l.jsx)(e.h3,{id:"overview-of-pddl",children:"Overview of PDDL"}),"\n",(0,l.jsx)(e.p,{children:"PDDL (Planning Domain Definition Language) is a formal language for describing planning problems in AI. It provides a standardized way to represent:"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Domain"}),": Types, predicates, and actions available"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Problem"}),": Initial state and goal conditions"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Plan"}),": Sequence of actions to achieve the goal"]}),"\n"]}),"\n",(0,l.jsx)(e.h3,{id:"pddl-structure-for-robotics",children:"PDDL Structure for Robotics"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'class PDDLDomain:\n    def __init__(self):\n        self.domain_name = "humanoid_robot_domain"\n        self.types = {\n            "location": ["kitchen", "living_room", "bedroom", "office"],\n            "object": ["cup", "bottle", "book", "phone"],\n            "robot": ["humanoid"]\n        }\n        self.predicates = [\n            "at(?robot - robot, ?loc - location)",\n            "holding(?robot - robot, ?obj - object)",\n            "object_at(?obj - object, ?loc - location)",\n            "reachable(?loc - location)",\n            "occupied(?loc - location)"\n        ]\n        self.actions = [\n            self.navigate_action(),\n            self.pick_action(),\n            self.place_action()\n        ]\n\n    def navigate_action(self):\n        return {\n            "name": "navigate",\n            "parameters": ["?robot - robot", "?from - location", "?to - location"],\n            "preconditions": [\n                "at(?robot, ?from)",\n                "reachable(?to)",\n                "not (= ?from ?to)"\n            ],\n            "effects": [\n                "at(?robot, ?to)",\n                "not at(?robot, ?from)"\n            ]\n        }\n\n    def pick_action(self):\n        return {\n            "name": "pick",\n            "parameters": ["?robot - robot", "?obj - object", "?loc - location"],\n            "preconditions": [\n                "at(?robot, ?loc)",\n                "object_at(?obj, ?loc)",\n                "not holding(?robot, ?obj)"\n            ],\n            "effects": [\n                "holding(?robot, ?obj)",\n                "not object_at(?obj, ?loc)"\n            ]\n        }\n\n    def place_action(self):\n        return {\n            "name": "place",\n            "parameters": ["?robot - robot", "?obj - object", "?loc - location"],\n            "preconditions": [\n                "at(?robot, ?loc)",\n                "holding(?robot, ?obj)"\n            ],\n            "effects": [\n                "object_at(?obj, ?loc)",\n                "not holding(?robot, ?obj)"\n            ]\n        }\n\nclass PDDLProblem:\n    def __init__(self, domain):\n        self.domain = domain\n        self.objects = {\n            "r1": "humanoid",\n            "c1": "cup",\n            "k1": "kitchen",\n            "l1": "living_room"\n        }\n        self.initial_state = [\n            "at(r1, k1)",\n            "object_at(c1, k1)",\n            "reachable(k1)",\n            "reachable(l1)"\n        ]\n        self.goal = [\n            "at(r1, l1)",\n            "object_at(c1, l1)"\n        ]\n'})}),"\n",(0,l.jsx)(e.h3,{id:"pddl-planning-with-external-solvers",children:"PDDL Planning with External Solvers"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'import subprocess\nimport tempfile\nimport os\n\nclass PDDLPlanner:\n    def __init__(self, planner_path="fast-downward"):\n        self.planner_path = planner_path\n\n    def solve_problem(self, domain, problem):\n        """\n        Solve PDDL problem using external planner\n        """\n        # Write domain and problem to temporary files\n        with tempfile.NamedTemporaryFile(mode=\'w\', suffix=\'.pddl\', delete=False) as domain_file:\n            domain_content = self.write_domain_file(domain)\n            domain_file.write(domain_content)\n            domain_path = domain_file.name\n\n        with tempfile.NamedTemporaryFile(mode=\'w\', suffix=\'.pddl\', delete=False) as problem_file:\n            problem_content = self.write_problem_file(problem)\n            problem_file.write(problem_content)\n            problem_path = problem_file.name\n\n        try:\n            # Call external planner\n            result = subprocess.run([\n                self.planner_path,\n                domain_path, problem_path,\n                "--search", "astar(lmcut())"\n            ], capture_output=True, text=True)\n\n            if result.returncode == 0:\n                plan = self.parse_plan(result.stdout)\n            else:\n                plan = None\n\n        finally:\n            # Clean up temporary files\n            os.unlink(domain_path)\n            os.unlink(problem_path)\n\n        return plan\n\n    def write_domain_file(self, domain):\n        """\n        Write PDDL domain file content\n        """\n        content = f"(define (domain {domain.domain_name})\\n"\n        content += "  (:requirements :strips :typing)\\n"\n\n        # Types\n        content += "  (:types\\n"\n        for type_name, instances in domain.types.items():\n            content += f"    {\' \'.join(instances)} - {type_name}\\n"\n        content += "  )\\n"\n\n        # Predicates\n        content += "  (:predicates\\n"\n        for pred in domain.predicates:\n            content += f"    ({pred})\\n"\n        content += "  )\\n"\n\n        # Actions\n        for action in domain.actions:\n            content += f"  (:action {action[\'name\']}\\n"\n            content += f"    :parameters ({\' \'.join(action[\'parameters\'])})\\n"\n            content += "    :precondition (and\\n"\n            for precond in action[\'preconditions\']:\n                content += f"      ({precond})\\n"\n            content += "    )\\n"\n            content += "    :effect (and\\n"\n            for effect in action[\'effects\']:\n                content += f"      ({effect})\\n"\n            content += "    )\\n"\n            content += "  )\\n"\n\n        content += ")\\n"\n        return content\n\n    def write_problem_file(self, problem):\n        """\n        Write PDDL problem file content\n        """\n        content = f"(define (problem task)\\n"\n        content += f"  (:domain {problem.domain.domain_name})\\n"\n\n        # Objects\n        content += "  (:objects\\n"\n        for obj_name, obj_type in problem.objects.items():\n            content += f"    {obj_name} - {obj_type}\\n"\n        content += "  )\\n"\n\n        # Initial state\n        content += "  (:init\\n"\n        for state in problem.initial_state:\n            content += f"    ({state})\\n"\n        content += "  )\\n"\n\n        # Goal\n        content += "  (:goal (and\\n"\n        for goal in problem.goal:\n            content += f"    ({goal})\\n"\n        content += "  ))\\n"\n        content += ")\\n"\n        return content\n\n    def parse_plan(self, plan_output):\n        """\n        Parse planner output into action sequence\n        """\n        lines = plan_output.split(\'\\n\')\n        plan = []\n        for line in lines:\n            if line.strip().startswith(\'(\') and line.strip().endswith(\')\'):\n                action = line.strip()[1:-1]  # Remove parentheses\n                plan.append(action)\n        return plan\n'})}),"\n",(0,l.jsx)(e.h2,{id:"llm-guided-task-planning",children:"LLM-Guided Task Planning"}),"\n",(0,l.jsx)(e.h3,{id:"natural-language-to-pddl-translation",children:"Natural Language to PDDL Translation"}),"\n",(0,l.jsx)(e.p,{children:"LLMs can bridge the gap between natural language and formal planning languages:"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'import openai\nfrom typing import Dict, List, Tuple\n\nclass LLMTaskPlanner:\n    def __init__(self, llm_model="gpt-3.5-turbo"):\n        self.llm_model = llm_model\n        self.pddl_planner = PDDLPlanner()\n\n    def plan_from_natural_language(self, command: str, world_state: Dict) -> List[str]:\n        """\n        Plan task from natural language command using LLM guidance\n        """\n        # Step 1: Parse natural language to structured representation\n        structured_task = self.parse_natural_language(command, world_state)\n\n        # Step 2: Convert to PDDL domain and problem\n        pddl_domain = self.create_pddl_domain(structured_task)\n        pddl_problem = self.create_pddl_problem(structured_task, world_state)\n\n        # Step 3: Solve using PDDL planner\n        plan = self.pddl_planner.solve_problem(pddl_domain, pddl_problem)\n\n        # Step 4: Refine plan using LLM for better executability\n        refined_plan = self.refine_plan_with_llm(plan, command, world_state)\n\n        return refined_plan\n\n    def parse_natural_language(self, command: str, world_state: Dict) -> Dict:\n        """\n        Parse natural language command into structured representation\n        """\n        prompt = f"""\n        Parse the following natural language command into structured task representation:\n\n        Command: "{command}"\n        World State: {world_state}\n\n        Provide the structured representation with:\n        1. Main task objective\n        2. Required objects\n        3. Target locations\n        4. Prerequisites\n        5. Expected outcome\n\n        Format the response as JSON.\n        """\n\n        response = openai.ChatCompletion.create(\n            model=self.llm_model,\n            messages=[{"role": "user", "content": prompt}]\n        )\n\n        import json\n        return json.loads(response.choices[0].message.content)\n\n    def create_pddl_domain(self, structured_task: Dict) -> PDDLDomain:\n        """\n        Create PDDL domain from structured task\n        """\n        domain = PDDLDomain()\n\n        # Customize domain based on task requirements\n        if "navigation" in structured_task.get("task_type", ""):\n            # Add navigation-specific predicates and actions\n            domain.predicates.extend([\n                "traversable(?from - location, ?to - location)",\n                "path_exists(?from - location, ?to - location)"\n            ])\n\n        if "manipulation" in structured_task.get("task_type", ""):\n            # Add manipulation-specific predicates and actions\n            domain.predicates.extend([\n                "graspable(?obj - object)",\n                "reachable(?obj - object)",\n                "free_hand(?robot - robot)"\n            ])\n\n        return domain\n\n    def create_pddl_problem(self, structured_task: Dict, world_state: Dict) -> PDDLProblem:\n        """\n        Create PDDL problem from structured task and world state\n        """\n        domain = self.create_pddl_domain(structured_task)\n\n        # Create problem object\n        problem = PDDLProblem(domain)\n\n        # Set objects based on world state\n        problem.objects = self.extract_objects_from_world_state(world_state)\n\n        # Set initial state\n        problem.initial_state = self.extract_initial_state(world_state)\n\n        # Set goal state\n        problem.goal = self.extract_goal_state(structured_task)\n\n        return problem\n\n    def extract_objects_from_world_state(self, world_state: Dict) -> Dict:\n        """\n        Extract objects from world state\n        """\n        objects = {}\n        # Extract from world state representation\n        for obj_name, obj_info in world_state.get("objects", {}).items():\n            obj_type = obj_info.get("type", "object")\n            objects[obj_name] = obj_type\n\n        for loc_name, loc_info in world_state.get("locations", {}).items():\n            objects[loc_name] = "location"\n\n        # Add robot\n        objects["robot1"] = "robot"\n\n        return objects\n\n    def extract_initial_state(self, world_state: Dict) -> List[str]:\n        """\n        Extract initial state from world state\n        """\n        initial_state = []\n\n        # Robot location\n        robot_pos = world_state.get("robot", {}).get("location", "unknown")\n        if robot_pos != "unknown":\n            initial_state.append(f"at(robot1, {robot_pos})")\n\n        # Object locations\n        for obj_name, obj_info in world_state.get("objects", {}).items():\n            obj_loc = obj_info.get("location", "unknown")\n            if obj_loc != "unknown":\n                initial_state.append(f"object_at({obj_name}, {obj_loc})")\n\n        # Reachable locations\n        for loc_name in world_state.get("locations", {}).keys():\n            initial_state.append(f"reachable({loc_name})")\n\n        return initial_state\n\n    def extract_goal_state(self, structured_task: Dict) -> List[str]:\n        """\n        Extract goal state from structured task\n        """\n        goal_state = []\n\n        # Parse task objective\n        objective = structured_task.get("objective", "")\n        if "bring" in objective.lower() or "fetch" in objective.lower():\n            # Goal: robot has object at target location\n            target_loc = structured_task.get("target_location", "unknown")\n            obj = structured_task.get("required_object", "unknown")\n            if target_loc != "unknown" and obj != "unknown":\n                goal_state.append(f"object_at({obj}, {target_loc})")\n\n        elif "go to" in objective.lower() or "navigate to" in objective.lower():\n            # Goal: robot at target location\n            target_loc = structured_task.get("target_location", "unknown")\n            if target_loc != "unknown":\n                goal_state.append(f"at(robot1, {target_loc})")\n\n        return goal_state\n\n    def refine_plan_with_llm(self, plan: List[str], command: str, world_state: Dict) -> List[str]:\n        """\n        Refine the PDDL-generated plan using LLM for better executability\n        """\n        if not plan:\n            return []\n\n        prompt = f"""\n        The following plan was generated for the command "{command}":\n        {plan}\n\n        World state: {world_state}\n\n        Refine this plan to make it more executable by a humanoid robot. Consider:\n        1. Physical constraints of humanoid locomotion\n        2. Grasping and manipulation requirements\n        3. Safety considerations\n        4. Natural human-like behavior\n\n        Return the refined plan as a list of executable actions.\n        """\n\n        response = openai.ChatCompletion.create(\n            model=self.llm_model,\n            messages=[{"role": "user", "content": prompt}]\n        )\n\n        import json\n        try:\n            refined_plan = json.loads(response.choices[0].message.content)\n            return refined_plan if isinstance(refined_plan, list) else plan\n        except:\n            # If parsing fails, return original plan\n            return plan\n'})}),"\n",(0,l.jsx)(e.h2,{id:"hierarchical-task-networks-htn",children:"Hierarchical Task Networks (HTN)"}),"\n",(0,l.jsx)(e.h3,{id:"htn-vs-pddl",children:"HTN vs PDDL"}),"\n",(0,l.jsx)(e.p,{children:"While PDDL focuses on state-based planning, Hierarchical Task Networks provide a more natural way to represent complex tasks by decomposing them hierarchically:"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'class HTNPlanner:\n    def __init__(self):\n        self.tasks = {\n            "fetch_object": self.decompose_fetch_object,\n            "navigate_to_room": self.decompose_navigate_to_room,\n            "manipulate_object": self.decompose_manipulate_object\n        }\n\n    def decompose_fetch_object(self, params):\n        """\n        Decompose fetch object task\n        """\n        return [\n            ("navigate_to_room", {"room": params["object_location"]}),\n            ("locate_object", {"object": params["object_name"]}),\n            ("grasp_object", {"object": params["object_name"]}),\n            ("navigate_to_room", {"room": params["delivery_location"]}),\n            ("place_object", {"object": params["object_name"], "location": params["delivery_location"]})\n        ]\n\n    def decompose_navigate_to_room(self, params):\n        """\n        Decompose navigate to room task\n        """\n        return [\n            ("find_path", {"destination": params["room"]}),\n            ("execute_path", {"destination": params["room"]}),\n            ("verify_arrival", {"location": params["room"]})\n        ]\n\n    def plan_with_htn(self, task, params):\n        """\n        Plan using HTN decomposition\n        """\n        if task in self.tasks:\n            subtasks = self.tasks[task](params)\n            plan = []\n            for subtask, subparams in subtasks:\n                if subtask in self.tasks:\n                    plan.extend(self.plan_with_htn(subtask, subparams))\n                else:\n                    plan.append((subtask, subparams))\n            return plan\n        else:\n            return [(task, params)]\n'})}),"\n",(0,l.jsx)(e.h2,{id:"integration-with-ros-2-task-planning",children:"Integration with ROS 2 Task Planning"}),"\n",(0,l.jsx)(e.h3,{id:"task-planning-node",children:"Task Planning Node"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import PoseStamped\nfrom action_msgs.msg import GoalStatus\nfrom ros2_task_planning_interfaces.srv import PlanTask\nfrom ros2_task_planning_interfaces.action import ExecuteTask\n\nclass LLMTaskPlanningNode(Node):\n    def __init__(self):\n        super().__init__(\'llm_task_planning_node\')\n\n        # Initialize LLM planner\n        self.llm_planner = LLMTaskPlanner()\n\n        # Service for task planning\n        self.plan_service = self.create_service(\n            PlanTask, \'plan_task\', self.plan_task_callback\n        )\n\n        # Action server for task execution\n        self.task_server = ActionServer(\n            self,\n            ExecuteTask,\n            \'execute_task\',\n            self.execute_task_callback\n        )\n\n        # Publishers for visualization\n        self.plan_pub = self.create_publisher(String, \'planned_tasks\', 10)\n        self.status_pub = self.create_publisher(String, \'task_status\', 10)\n\n        # World state subscriber\n        self.world_state_sub = self.create_subscription(\n            String, \'world_state\', self.world_state_callback, 10\n        )\n\n        self.current_world_state = {}\n\n    def plan_task_callback(self, request, response):\n        """\n        Service callback for task planning\n        """\n        try:\n            # Get current world state\n            world_state = self.current_world_state\n\n            # Plan task using LLM\n            plan = self.llm_planner.plan_from_natural_language(\n                request.command, world_state\n            )\n\n            response.plan = plan\n            response.success = len(plan) > 0\n            response.error_message = "" if response.success else "Failed to generate plan"\n\n            # Publish plan for visualization\n            plan_msg = String()\n            plan_msg.data = str(plan)\n            self.plan_pub.publish(plan_msg)\n\n        except Exception as e:\n            response.success = False\n            response.error_message = str(e)\n            self.get_logger().error(f"Task planning failed: {e}")\n\n        return response\n\n    def execute_task_callback(self, goal_handle):\n        """\n        Action callback for task execution\n        """\n        command = goal_handle.request.command\n        self.get_logger().info(f\'Executing task: {command}\')\n\n        # Get current world state\n        world_state = self.current_world_state\n\n        # Plan the task\n        plan = self.llm_planner.plan_from_natural_language(command, world_state)\n\n        if not plan:\n            goal_handle.abort()\n            result = ExecuteTask.Result()\n            result.success = False\n            result.message = "Could not generate plan"\n            return result\n\n        # Execute the plan step by step\n        for i, action in enumerate(plan):\n            if goal_handle.is_cancel_requested:\n                goal_handle.canceled()\n                result = ExecuteTask.Result()\n                result.success = False\n                result.message = "Task canceled"\n                return result\n\n            # Execute individual action\n            action_success = self.execute_action(action)\n\n            if not action_success:\n                goal_handle.abort()\n                result = ExecuteTask.Result()\n                result.success = False\n                result.message = f"Action failed: {action}"\n                return result\n\n            # Update feedback\n            feedback = ExecuteTask.Feedback()\n            feedback.current_action = str(action)\n            feedback.progress = float(i + 1) / len(plan)\n            goal_handle.publish_feedback(feedback)\n\n        # Task completed successfully\n        goal_handle.succeed()\n        result = ExecuteTask.Result()\n        result.success = True\n        result.message = "Task completed successfully"\n        return result\n\n    def execute_action(self, action):\n        """\n        Execute a single action primitive\n        """\n        # This would interface with the robot\'s action execution system\n        # For simulation, we\'ll return success\n        self.get_logger().info(f\'Executing action: {action}\')\n        return True\n\n    def world_state_callback(self, msg):\n        """\n        Update world state from message\n        """\n        import json\n        try:\n            self.current_world_state = json.loads(msg.data)\n        except:\n            self.get_logger().warn("Could not parse world state message")\n'})}),"\n",(0,l.jsx)(e.h2,{id:"llm-enhanced-planning-strategies",children:"LLM-Enhanced Planning Strategies"}),"\n",(0,l.jsx)(e.h3,{id:"context-aware-planning",children:"Context-Aware Planning"}),"\n",(0,l.jsx)(e.p,{children:"LLMs can incorporate contextual information to improve planning:"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'class ContextAwarePlanner:\n    def __init__(self, llm_planner):\n        self.llm_planner = llm_planner\n        self.context_memory = []\n\n    def plan_with_context(self, command, world_state, context_history=None):\n        """\n        Plan task considering contextual information\n        """\n        # Combine current context with historical context\n        full_context = self.build_context(world_state, context_history)\n\n        # Include context in planning prompt\n        prompt = f"""\n        Plan the following task considering the provided context:\n\n        Command: {command}\n        Current World State: {world_state}\n        Context History: {full_context}\n\n        Generate a plan that accounts for:\n        1. Previous similar tasks\n        2. Known preferences or routines\n        3. Environmental constraints\n        4. Safety considerations\n\n        Return the plan as a sequence of actions.\n        """\n\n        # Use LLM to generate context-aware plan\n        response = openai.ChatCompletion.create(\n            model="gpt-3.5-turbo",\n            messages=[{"role": "user", "content": prompt}]\n        )\n\n        import json\n        try:\n            plan = json.loads(response.choices[0].message.content)\n            return plan\n        except:\n            return []\n\n    def build_context(self, current_state, history=None):\n        """\n        Build contextual information for planning\n        """\n        context = {\n            "time_of_day": self.get_time_of_day(),\n            "day_of_week": self.get_day_of_week(),\n            "previous_tasks": self.get_recent_tasks(),\n            "user_preferences": self.get_user_preferences(),\n            "environmental_conditions": self.get_environmental_conditions(current_state)\n        }\n        return context\n\n    def get_time_of_day(self):\n        """\n        Get current time of day\n        """\n        import datetime\n        hour = datetime.datetime.now().hour\n        if 5 <= hour < 12:\n            return "morning"\n        elif 12 <= hour < 17:\n            return "afternoon"\n        elif 17 <= hour < 21:\n            return "evening"\n        else:\n            return "night"\n'})}),"\n",(0,l.jsx)(e.h3,{id:"multi-modal-planning",children:"Multi-Modal Planning"}),"\n",(0,l.jsx)(e.p,{children:"Integrate visual information with LLM planning:"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'class MultiModalPlanner:\n    def __init__(self, llm_planner, vision_system):\n        self.llm_planner = llm_planner\n        self.vision_system = vision_system\n\n    def plan_with_visual_context(self, command, image):\n        """\n        Plan task using both natural language and visual context\n        """\n        # Analyze image to extract relevant information\n        visual_context = self.vision_system.analyze_scene(image)\n\n        # Combine with natural language command\n        prompt = f"""\n        Task Command: {command}\n        Visual Context: {visual_context}\n\n        Plan the task considering both the natural language command and the visual scene.\n        Take into account:\n        1. Objects visible in the scene\n        2. Spatial relationships between objects\n        3. Accessibility of objects\n        4. Potential obstacles\n\n        Provide a detailed plan with specific actions.\n        """\n\n        response = openai.ChatCompletion.create(\n            model="gpt-3.5-turbo",\n            messages=[{"role": "user", "content": prompt}]\n        )\n\n        import json\n        try:\n            plan = json.loads(response.choices[0].message.content)\n            return plan\n        except:\n            return []\n'})}),"\n",(0,l.jsx)(e.h2,{id:"handling-uncertainty-and-failures",children:"Handling Uncertainty and Failures"}),"\n",(0,l.jsx)(e.h3,{id:"plan-monitoring-and-recovery",children:"Plan Monitoring and Recovery"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'class AdaptiveTaskPlanner:\n    def __init__(self, base_planner):\n        self.base_planner = base_planner\n        self.failure_recovery = {\n            "navigation_failure": self.handle_navigation_failure,\n            "grasping_failure": self.handle_grasping_failure,\n            "object_not_found": self.handle_object_not_found\n        }\n\n    def execute_with_monitoring(self, command, world_state):\n        """\n        Execute plan with monitoring and recovery\n        """\n        plan = self.base_planner.plan_from_natural_language(command, world_state)\n\n        for i, action in enumerate(plan):\n            try:\n                result = self.execute_action_with_monitoring(action)\n\n                if not result.success:\n                    # Handle failure\n                    recovery_plan = self.handle_failure(result.error_type, action, plan[i+1:])\n                    plan = plan[:i] + recovery_plan + plan[i+1:]\n\n            except Exception as e:\n                # Unexpected failure\n                recovery_plan = self.handle_unexpected_failure(str(e), action, plan[i+1:])\n                plan = plan[:i] + recovery_plan + plan[i+1:]\n\n        return plan\n\n    def handle_failure(self, error_type, failed_action, remaining_plan):\n        """\n        Generate recovery plan for specific failure type\n        """\n        if error_type in self.failure_recovery:\n            return self.failure_recovery[error_type](failed_action, remaining_plan)\n        else:\n            # General recovery\n            return self.generate_general_recovery(failed_action, remaining_plan)\n\n    def handle_navigation_failure(self, failed_action, remaining_plan):\n        """\n        Handle navigation failure\n        """\n        # Try alternative path\n        alternative_paths = self.find_alternative_paths(failed_action)\n        if alternative_paths:\n            return alternative_paths[0] + remaining_plan\n        else:\n            return [("report_failure", {"reason": "No alternative path available"})]\n\n    def handle_grasping_failure(self, failed_action, remaining_plan):\n        """\n        Handle grasping failure\n        """\n        # Try different grasp approach\n        return [("adjust_grasp", {}), failed_action] + remaining_plan\n\n    def handle_object_not_found(self, failed_action, remaining_plan):\n        """\n        Handle object not found failure\n        """\n        # Search for object in other locations\n        search_actions = self.generate_search_plan(failed_action)\n        return search_actions + [failed_action] + remaining_plan\n'})}),"\n",(0,l.jsx)(e.h2,{id:"performance-optimization-and-best-practices",children:"Performance Optimization and Best Practices"}),"\n",(0,l.jsx)(e.h3,{id:"1-plan-caching",children:"1. Plan Caching"}),"\n",(0,l.jsx)(e.p,{children:"Cache frequently executed plans to improve efficiency:"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'class CachedTaskPlanner:\n    def __init__(self, base_planner):\n        self.base_planner = base_planner\n        self.plan_cache = {}\n        self.cache_size_limit = 100\n\n    def plan_from_natural_language(self, command, world_state):\n        """\n        Plan with caching\n        """\n        cache_key = self.generate_cache_key(command, world_state)\n\n        if cache_key in self.plan_cache:\n            self.get_logger().info("Retrieved plan from cache")\n            return self.plan_cache[cache_key]\n\n        # Generate new plan\n        plan = self.base_planner.plan_from_natural_language(command, world_state)\n\n        # Add to cache\n        if len(self.plan_cache) < self.cache_size_limit:\n            self.plan_cache[cache_key] = plan\n\n        return plan\n\n    def generate_cache_key(self, command, world_state):\n        """\n        Generate cache key from command and simplified world state\n        """\n        # Simplify world state for caching purposes\n        simplified_state = self.simplify_world_state(world_state)\n        return f"{command}_{hash(str(simplified_state))}"\n'})}),"\n",(0,l.jsx)(e.h3,{id:"2-hierarchical-plan-execution",children:"2. Hierarchical Plan Execution"}),"\n",(0,l.jsx)(e.p,{children:"Execute plans in a hierarchical manner with proper error handling:"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'class HierarchicalExecutor:\n    def __init__(self):\n        self.executors = {\n            "high_level": self.execute_high_level,\n            "mid_level": self.execute_mid_level,\n            "low_level": self.execute_low_level\n        }\n\n    def execute_plan(self, plan):\n        """\n        Execute plan hierarchically\n        """\n        for task in plan:\n            level = self.determine_task_level(task)\n            result = self.executors[level](task)\n            if not result.success:\n                return result\n        return {"success": True, "message": "Plan completed"}\n'})}),"\n",(0,l.jsx)(e.h2,{id:"future-directions-and-research",children:"Future Directions and Research"}),"\n",(0,l.jsx)(e.h3,{id:"1-learning-from-execution",children:"1. Learning from Execution"}),"\n",(0,l.jsx)(e.p,{children:"Adapt planning based on execution experience:"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'class LearningPlanner:\n    def __init__(self):\n        self.execution_history = []\n        self.success_rates = {}\n\n    def update_from_execution(self, command, plan, result):\n        """\n        Update planner based on execution results\n        """\n        self.execution_history.append({\n            "command": command,\n            "plan": plan,\n            "result": result,\n            "timestamp": time.time()\n        })\n\n        # Update success rates\n        plan_str = str(plan)\n        if plan_str not in self.success_rates:\n            self.success_rates[plan_str] = {"success": 0, "total": 0}\n\n        self.success_rates[plan_str]["total"] += 1\n        if result.get("success", False):\n            self.success_rates[plan_str]["success"] += 1\n'})}),"\n",(0,l.jsx)(e.h3,{id:"2-collaborative-planning",children:"2. Collaborative Planning"}),"\n",(0,l.jsx)(e.p,{children:"Plan tasks that involve multiple robots or human-robot collaboration:"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'class CollaborativePlanner:\n    def __init__(self):\n        self.robot_capabilities = {}\n        self.human_capabilities = {}\n\n    def plan_collaborative_task(self, command, participants):\n        """\n        Plan task involving multiple participants\n        """\n        # Assign subtasks based on capabilities\n        task_allocation = self.allocate_tasks(command, participants)\n        synchronized_plan = self.synchronize_plans(task_allocation)\n        return synchronized_plan\n'})}),"\n",(0,l.jsx)(e.p,{children:"High-level task planning using LLMs represents a significant advancement in robotics, enabling natural human-robot interaction and sophisticated reasoning capabilities that allow robots to understand and execute complex, abstract commands in real-world environments."})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,l.jsx)(e,{...n,children:(0,l.jsx)(d,{...n})}):d(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>i,x:()=>s});var a=t(6540);const l={},o=a.createContext(l);function i(n){const e=a.useContext(o);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(l):n.components||l:i(n.components),a.createElement(o.Provider,{value:e},n.children)}}}]);