"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[359],{8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var s=t(6540);const i={},a=s.createContext(i);function r(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:n},e.children)}},9070:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-04/real-world-deployment","title":"Real-World Deployment and Challenges","description":"Introduction to Sim-to-Real Transfer","source":"@site/docs/module-04/19-real-world-deployment.md","sourceDirName":"module-04","slug":"/module-04/real-world-deployment","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-04/real-world-deployment","draft":false,"unlisted":false,"editUrl":"https://github.com/alismehtab7-125/Physical-AI-Humanoid-Robotics/edit/main/docs/module-04/19-real-world-deployment.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Real-World Deployment and Challenges"},"sidebar":"tutorialSidebar","previous":{"title":"High-Level Task Planning using LLMs","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-04/high-level-task-planning"},"next":{"title":"Capstone Project: Autonomous Humanoid Agent","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-04/capstone-project"}}');var i=t(4848),a=t(8453);const r={sidebar_position:4,title:"Real-World Deployment and Challenges"},o="Real-World Deployment and Challenges",l={},c=[{value:"Introduction to Sim-to-Real Transfer",id:"introduction-to-sim-to-real-transfer",level:2},{value:"The Reality Gap Problem",id:"the-reality-gap-problem",level:3},{value:"Calibration and System Identification",id:"calibration-and-system-identification",level:2},{value:"Sensor Calibration",id:"sensor-calibration",level:3},{value:"Camera Calibration",id:"camera-calibration",level:4},{value:"IMU Calibration",id:"imu-calibration",level:4},{value:"Kinematic Calibration",id:"kinematic-calibration",level:3},{value:"Latency and Timing Considerations",id:"latency-and-timing-considerations",level:2},{value:"Communication Latency",id:"communication-latency",level:3},{value:"Real-Time Performance Optimization",id:"real-time-performance-optimization",level:3},{value:"Safety Protocols and Emergency Procedures",id:"safety-protocols-and-emergency-procedures",level:2},{value:"Safety Monitoring System",id:"safety-monitoring-system",level:3},{value:"Emergency Stop System",id:"emergency-stop-system",level:3},{value:"Hardware-Specific Considerations",id:"hardware-specific-considerations",level:2},{value:"Power Management",id:"power-management",level:3},{value:"Thermal Management",id:"thermal-management",level:3},{value:"Testing and Validation Strategies",id:"testing-and-validation-strategies",level:2},{value:"Gradual Deployment Approach",id:"gradual-deployment-approach",level:3},{value:"A/B Testing Framework",id:"ab-testing-framework",level:3},{value:"Troubleshooting Common Deployment Issues",id:"troubleshooting-common-deployment-issues",level:2},{value:"1. Actuator Saturation",id:"1-actuator-saturation",level:3},{value:"2. Sensor Noise and Drift",id:"2-sensor-noise-and-drift",level:3},{value:"3. Model Parameter Mismatch",id:"3-model-parameter-mismatch",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"real-world-deployment-and-challenges",children:"Real-World Deployment and Challenges"})}),"\n",(0,i.jsx)(n.h2,{id:"introduction-to-sim-to-real-transfer",children:"Introduction to Sim-to-Real Transfer"}),"\n",(0,i.jsx)(n.p,{children:'The transition from simulation to real-world deployment represents one of the most challenging aspects of humanoid robotics development. While simulation environments provide safe, controlled, and cost-effective platforms for developing and testing robot behaviors, the "reality gap" between simulated and physical environments can lead to significant performance degradation when transferring learned policies and control systems to actual hardware.'}),"\n",(0,i.jsx)(n.h3,{id:"the-reality-gap-problem",children:"The Reality Gap Problem"}),"\n",(0,i.jsx)(n.p,{children:"The reality gap encompasses all the differences between simulation and reality that can affect robot performance:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Physical Properties"}),": Differences in mass, friction, elasticity, and other physical parameters"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensor Characteristics"}),": Noise, latency, calibration errors, and limited field of view"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actuator Dynamics"}),": Motor backlash, dead zones, saturation limits, and response delays"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Environmental Factors"}),": Lighting conditions, surface variations, and external disturbances"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Computational Constraints"}),": Processing delays, memory limitations, and power constraints"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"calibration-and-system-identification",children:"Calibration and System Identification"}),"\n",(0,i.jsx)(n.h3,{id:"sensor-calibration",children:"Sensor Calibration"}),"\n",(0,i.jsx)(n.p,{children:"Accurate sensor calibration is crucial for successful real-world deployment:"}),"\n",(0,i.jsx)(n.h4,{id:"camera-calibration",children:"Camera Calibration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import cv2\nimport numpy as np\n\ndef calibrate_camera(images, checkerboard_size=(9, 6)):\n    """\n    Calibrate camera using checkerboard pattern\n    """\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n\n    # Prepare object points\n    objp = np.zeros((checkerboard_size[0] * checkerboard_size[1], 3), np.float32)\n    objp[:, :2] = np.mgrid[0:checkerboard_size[0], 0:checkerboard_size[1]].T.reshape(-1, 2)\n\n    objpoints = []  # 3d points in real world space\n    imgpoints = []  # 2d points in image plane\n\n    for img in images:\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n        # Find chessboard corners\n        ret, corners = cv2.findChessboardCorners(gray, checkerboard_size, None)\n\n        if ret:\n            objpoints.append(objp)\n            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n            imgpoints.append(corners2)\n\n    # Perform calibration\n    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n        objpoints, imgpoints, gray.shape[::-1], None, None\n    )\n\n    return mtx, dist  # Camera matrix and distortion coefficients\n'})}),"\n",(0,i.jsx)(n.h4,{id:"imu-calibration",children:"IMU Calibration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class IMUCalibrator:\n    def __init__(self):\n        self.accel_bias = np.zeros(3)\n        self.gyro_bias = np.zeros(3)\n        self.accel_scale = np.ones(3)\n        self.gyro_scale = np.ones(3)\n\n    def calibrate_accelerometer(self, static_readings, expected_gravity=9.81):\n        """\n        Calibrate accelerometer by collecting static readings\n        """\n        # Average readings to get bias\n        avg_reading = np.mean(static_readings, axis=0)\n\n        # Calculate magnitude to determine gravity direction\n        magnitude = np.linalg.norm(avg_reading)\n\n        # Gravity should point in -Z direction (assuming robot is upright)\n        expected_vector = np.array([0, 0, -expected_gravity])\n\n        # Calculate scale factor\n        scale_factor = expected_gravity / magnitude\n\n        # Calculate bias\n        self.accel_bias = avg_reading - expected_vector / scale_factor\n        self.accel_scale = np.array([scale_factor, scale_factor, scale_factor])\n\n        return self.accel_bias, self.accel_scale\n\n    def calibrate_gyroscope(self, static_readings):\n        """\n        Calibrate gyroscope by averaging readings during static periods\n        """\n        # Gyro bias is the average reading when stationary\n        self.gyro_bias = np.mean(static_readings, axis=0)\n\n        return self.gyro_bias\n'})}),"\n",(0,i.jsx)(n.h3,{id:"kinematic-calibration",children:"Kinematic Calibration"}),"\n",(0,i.jsx)(n.p,{children:"Accurate kinematic parameters are essential for precise control:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class KinematicCalibrator:\n    def __init__(self, robot_description):\n        self.robot_description = robot_description\n        self.original_parameters = self.extract_kinematic_parameters()\n        self.calibrated_parameters = self.original_parameters.copy()\n\n    def calibrate_link_lengths(self, measured_positions, expected_positions):\n        """\n        Calibrate link lengths using measured vs expected end-effector positions\n        """\n        # Use optimization to minimize position error\n        from scipy.optimize import minimize\n\n        def position_error(params):\n            # Update robot model with new parameters\n            self.update_kinematic_parameters(params)\n\n            # Calculate forward kinematics\n            calculated_positions = self.forward_kinematics()\n\n            # Calculate error\n            error = np.sum((calculated_positions - expected_positions) ** 2)\n            return error\n\n        # Optimize parameters\n        result = minimize(position_error, self.calibrated_parameters)\n\n        return result.x\n\n    def calibrate_joint_offsets(self, encoder_readings, expected_angles):\n        """\n        Calibrate joint angle offsets\n        """\n        joint_offsets = expected_angles - encoder_readings\n        return joint_offsets\n'})}),"\n",(0,i.jsx)(n.h2,{id:"latency-and-timing-considerations",children:"Latency and Timing Considerations"}),"\n",(0,i.jsx)(n.h3,{id:"communication-latency",children:"Communication Latency"}),"\n",(0,i.jsx)(n.p,{children:"Real-world deployment introduces various sources of latency:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import time\nimport threading\nfrom collections import deque\n\nclass LatencyMonitor:\n    def __init__(self, window_size=100):\n        self.latency_buffer = deque(maxlen=window_size)\n        self.lock = threading.Lock()\n\n    def measure_latency(self, send_time, receive_time):\n        """\n        Measure round-trip latency\n        """\n        latency = receive_time - send_time\n        with self.lock:\n            self.latency_buffer.append(latency)\n        return latency\n\n    def get_statistics(self):\n        """\n        Get latency statistics\n        """\n        if not self.latency_buffer:\n            return {"mean": 0, "std": 0, "min": 0, "max": 0}\n\n        latencies = list(self.latency_buffer)\n        return {\n            "mean": np.mean(latencies),\n            "std": np.std(latencies),\n            "min": np.min(latencies),\n            "max": np.max(latencies),\n            "p95": np.percentile(latencies, 95)\n        }\n\nclass RealtimeController:\n    def __init__(self, control_frequency=100):\n        self.control_period = 1.0 / control_frequency\n        self.latency_monitor = LatencyMonitor()\n        self.compensated_control = True\n\n    def execute_control_step(self, state, desired_action):\n        """\n        Execute control step with latency compensation\n        """\n        start_time = time.time()\n\n        if self.compensated_control:\n            # Predict state based on latency\n            predicted_state = self.predict_state_with_latency(state)\n            control_output = self.compute_control(predicted_state, desired_action)\n        else:\n            control_output = self.compute_control(state, desired_action)\n\n        # Apply control output\n        self.apply_control_output(control_output)\n\n        # Measure execution time\n        execution_time = time.time() - start_time\n        latency = max(0, self.control_period - execution_time)\n\n        if latency > 0:\n            time.sleep(latency)\n\n        return control_output\n'})}),"\n",(0,i.jsx)(n.h3,{id:"real-time-performance-optimization",children:"Real-Time Performance Optimization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import multiprocessing as mp\nfrom concurrent.futures import ThreadPoolExecutor\nimport numpy as np\n\nclass RealtimeOptimizer:\n    def __init__(self):\n        self.process_pool = mp.Pool(processes=4)\n        self.thread_pool = ThreadPoolExecutor(max_workers=8)\n\n    def optimize_control_pipeline(self, sensor_data):\n        """\n        Optimize control pipeline for real-time performance\n        """\n        # Parallel processing of different sensor modalities\n        futures = {\n            \'vision\': self.thread_pool.submit(self.process_vision, sensor_data[\'camera\']),\n            \'imu\': self.thread_pool.submit(self.process_imu, sensor_data[\'imu\']),\n            \'lidar\': self.thread_pool.submit(self.process_lidar, sensor_data[\'lidar\']),\n            \'force\': self.thread_pool.submit(self.process_force, sensor_data[\'force\'])\n        }\n\n        # Collect results\n        processed_data = {}\n        for key, future in futures.items():\n            processed_data[key] = future.result(timeout=0.01)  # 10ms timeout\n\n        return processed_data\n\n    def process_vision(self, image_data):\n        """\n        Process vision data with optimized pipeline\n        """\n        # Use optimized computer vision operations\n        # Resize, normalize, and run inference efficiently\n        pass\n\n    def process_imu(self, imu_data):\n        """\n        Process IMU data efficiently\n        """\n        # Apply filtering and integration with optimized algorithms\n        pass\n'})}),"\n",(0,i.jsx)(n.h2,{id:"safety-protocols-and-emergency-procedures",children:"Safety Protocols and Emergency Procedures"}),"\n",(0,i.jsx)(n.h3,{id:"safety-monitoring-system",children:"Safety Monitoring System"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class SafetyMonitor:\n    def __init__(self):\n        self.safety_limits = {\n            'joint_position': {'min': -3.14, 'max': 3.14},\n            'joint_velocity': {'max': 5.0},\n            'joint_torque': {'max': 100.0},\n            'base_velocity': {'linear': 1.0, 'angular': 1.0},\n            'power_consumption': {'max': 500.0}\n        }\n        self.emergency_stop_active = False\n        self.violation_history = []\n\n    def check_safety_constraints(self, robot_state):\n        \"\"\"\n        Check if current robot state violates safety constraints\n        \"\"\"\n        violations = []\n\n        # Check joint limits\n        for i, joint_pos in enumerate(robot_state.joint_positions):\n            if (joint_pos < self.safety_limits['joint_position']['min'] or\n                joint_pos > self.safety_limits['joint_position']['max']):\n                violations.append(f\"Joint {i} position limit violated: {joint_pos}\")\n\n        # Check joint velocities\n        for i, joint_vel in enumerate(robot_state.joint_velocities):\n            if abs(joint_vel) > self.safety_limits['joint_velocity']['max']:\n                violations.append(f\"Joint {i} velocity limit violated: {joint_vel}\")\n\n        # Check joint torques\n        for i, joint_torque in enumerate(robot_state.joint_torques):\n            if abs(joint_torque) > self.safety_limits['joint_torque']['max']:\n                violations.append(f\"Joint {i} torque limit violated: {joint_torque}\")\n\n        # Check base velocity\n        if (abs(robot_state.base_linear_vel) > self.safety_limits['base_velocity']['linear'] or\n            abs(robot_state.base_angular_vel) > self.safety_limits['base_velocity']['angular']):\n            violations.append(\"Base velocity limit violated\")\n\n        # Check power consumption\n        if robot_state.power_consumption > self.safety_limits['power_consumption']['max']:\n            violations.append(\"Power consumption limit violated\")\n\n        if violations:\n            self.violation_history.extend(violations)\n            self.trigger_safety_procedures(violations)\n\n        return len(violations) == 0\n\n    def trigger_safety_procedures(self, violations):\n        \"\"\"\n        Trigger appropriate safety procedures based on violations\n        \"\"\"\n        if self.is_fall_imminent():\n            self.execute_fall_prevention()\n        else:\n            self.execute_safe_stop()\n\n        # Log violations\n        for violation in violations:\n            self.log_safety_violation(violation)\n\n    def is_fall_imminent(self):\n        \"\"\"\n        Determine if robot is about to fall based on current state\n        \"\"\"\n        # Check ZMP (Zero Moment Point) stability\n        zmp = self.calculate_zmp()\n        support_polygon = self.calculate_support_polygon()\n\n        return not self.is_zmp_in_support_polygon(zmp, support_polygon)\n\n    def execute_safe_stop(self):\n        \"\"\"\n        Execute safe stop procedure\n        \"\"\"\n        # Gradually reduce all joint torques to zero\n        # Move to safe posture if possible\n        # Log the event\n        self.emergency_stop_active = True\n        self.apply_zero_torques()\n        self.log_safety_event(\"Safe stop executed\")\n"})}),"\n",(0,i.jsx)(n.h3,{id:"emergency-stop-system",children:"Emergency Stop System"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import signal\nimport sys\n\nclass EmergencyStopSystem:\n    def __init__(self, robot_interface):\n        self.robot_interface = robot_interface\n        self.emergency_stop_active = False\n        self.last_safe_state = None\n\n        # Register signal handlers\n        signal.signal(signal.SIGINT, self.signal_handler)\n        signal.signal(signal.SIGTERM, self.signal_handler)\n\n    def signal_handler(self, signum, frame):\n        """\n        Handle system signals for emergency stop\n        """\n        print(f"Emergency stop triggered by signal {signum}")\n        self.trigger_emergency_stop()\n        sys.exit(0)\n\n    def trigger_emergency_stop(self):\n        """\n        Trigger emergency stop\n        """\n        if not self.emergency_stop_active:\n            self.emergency_stop_active = True\n\n            # Save current state for recovery\n            self.last_safe_state = self.robot_interface.get_current_state()\n\n            # Apply emergency stop to robot\n            self.robot_interface.emergency_stop()\n\n            # Log the event\n            self.log_emergency_event("Emergency stop activated")\n\n    def is_emergency_stop_active(self):\n        """\n        Check if emergency stop is active\n        """\n        return self.emergency_stop_active\n\n    def clear_emergency_stop(self):\n        """\n        Clear emergency stop (after addressing the issue)\n        """\n        if self.emergency_stop_active:\n            self.emergency_stop_active = False\n            self.log_emergency_event("Emergency stop cleared")\n            return True\n        return False\n'})}),"\n",(0,i.jsx)(n.h2,{id:"hardware-specific-considerations",children:"Hardware-Specific Considerations"}),"\n",(0,i.jsx)(n.h3,{id:"power-management",children:"Power Management"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class PowerManager:\n    def __init__(self, battery_capacity=100.0):  # Wh\n        self.battery_capacity = battery_capacity\n        self.current_charge = battery_capacity\n        self.power_consumption_history = []\n        self.low_power_threshold = 0.2  # 20% remaining\n\n    def estimate_power_consumption(self, robot_state, planned_actions):\n        """\n        Estimate power consumption for planned actions\n        """\n        base_consumption = self.calculate_base_consumption(robot_state)\n        action_consumption = self.calculate_action_consumption(planned_actions)\n\n        total_consumption = base_consumption + action_consumption\n        return total_consumption\n\n    def calculate_base_consumption(self, robot_state):\n        """\n        Calculate base power consumption based on current state\n        """\n        # Calculate power consumption for each joint\n        joint_consumption = 0\n        for i, (torque, velocity) in enumerate(\n            zip(robot_state.joint_torques, robot_state.joint_velocities)\n        ):\n            # Power = torque * angular_velocity\n            joint_power = abs(torque * velocity)\n            joint_consumption += joint_power\n\n        # Add other system power consumption\n        system_power = 50.0  # Fixed power for sensors, computers, etc.\n\n        return joint_consumption + system_power\n\n    def predict_remaining_operating_time(self):\n        """\n        Predict remaining operating time based on current consumption rate\n        """\n        if not self.power_consumption_history:\n            return float(\'inf\')\n\n        avg_consumption = np.mean(self.power_consumption_history[-10:])  # Last 10 measurements\n        remaining_energy = self.current_charge * self.low_power_threshold\n        remaining_time = remaining_energy / avg_consumption if avg_consumption > 0 else float(\'inf\')\n\n        return remaining_time\n\n    def enforce_power_limits(self, planned_actions):\n        """\n        Modify planned actions to stay within power limits\n        """\n        max_power = self.battery_capacity * 0.8  # Use 80% of capacity\n\n        if self.current_charge / self.battery_capacity < self.low_power_threshold:\n            # Enter power-saving mode\n            return self.modify_actions_for_power_saving(planned_actions)\n\n        return planned_actions\n'})}),"\n",(0,i.jsx)(n.h3,{id:"thermal-management",children:"Thermal Management"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class ThermalManager:\n    def __init__(self):\n        self.temperature_limits = {\n            'motors': {'max': 80, 'critical': 90},\n            'electronics': {'max': 70, 'critical': 80},\n            'cpu': {'max': 85, 'critical': 95}\n        }\n        self.cooling_active = False\n\n    def monitor_temperatures(self, temperature_readings):\n        \"\"\"\n        Monitor component temperatures and take action if needed\n        \"\"\"\n        for component, temp in temperature_readings.items():\n            if component in self.temperature_limits:\n                limits = self.temperature_limits[component]\n\n                if temp > limits['critical']:\n                    self.trigger_critical_cooling_procedure(component, temp)\n                elif temp > limits['max']:\n                    self.trigger_cooling_procedure(component, temp)\n\n    def trigger_cooling_procedure(self, component, temperature):\n        \"\"\"\n        Trigger cooling procedure for component\n        \"\"\"\n        print(f\"Warning: {component} temperature high: {temperature}\xb0C\")\n\n        # Reduce performance to lower heat generation\n        self.reduce_component_performance(component)\n\n        # Activate cooling if available\n        if self.has_cooling_system():\n            self.activate_cooling_system()\n\n    def trigger_critical_cooling_procedure(self, component, temperature):\n        \"\"\"\n        Trigger critical cooling procedure\n        \"\"\"\n        print(f\"Critical: {component} temperature very high: {temperature}\xb0C\")\n\n        # Reduce performance significantly\n        self.reduce_component_performance(component, factor=0.5)\n\n        # Activate maximum cooling\n        self.activate_cooling_system(maximum=True)\n\n        # If temperature continues to rise, trigger emergency stop\n        if temperature > self.temperature_limits[component]['critical'] + 5:\n            self.trigger_emergency_stop()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"testing-and-validation-strategies",children:"Testing and Validation Strategies"}),"\n",(0,i.jsx)(n.h3,{id:"gradual-deployment-approach",children:"Gradual Deployment Approach"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class GradualDeployment:\n    def __init__(self):\n        self.deployment_level = 0  # 0 = simulation only, 5 = full autonomy\n        self.performance_thresholds = [0.6, 0.7, 0.8, 0.9, 0.95]  # Success rates\n        self.deployment_levels = [\n            "simulation_only",\n            "teleoperation_with_assistance",\n            "limited_autonomy",\n            "extended_autonomy",\n            "full_autonomy"\n        ]\n\n    def evaluate_performance(self, task_results):\n        """\n        Evaluate performance to determine if ready for next deployment level\n        """\n        success_rate = self.calculate_success_rate(task_results)\n\n        if success_rate >= self.performance_thresholds[self.deployment_level]:\n            if self.deployment_level < len(self.performance_thresholds) - 1:\n                self.deployment_level += 1\n                print(f"Advancing to deployment level: {self.deployment_levels[self.deployment_level]}")\n                return True\n\n        return False\n\n    def calculate_success_rate(self, task_results):\n        """\n        Calculate success rate from task results\n        """\n        if not task_results:\n            return 0.0\n\n        successful_tasks = sum(1 for result in task_results if result.success)\n        return successful_tasks / len(task_results)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"ab-testing-framework",children:"A/B Testing Framework"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import random\nfrom enum import Enum\n\nclass ControlMode(Enum):\n    SIMULATION_BASED = "simulation_based"\n    REAL_WORLD_ADAPTED = "real_world_adapted"\n    HYBRID = "hybrid"\n\nclass ABAutomationTest:\n    def __init__(self):\n        self.test_results = {}\n        self.current_mode = ControlMode.SIMULATION_BASED\n\n    def run_ab_test(self, task_list, modes=[ControlMode.SIMULATION_BASED, ControlMode.REAL_WORLD_ADAPTED]):\n        """\n        Run A/B test comparing different control modes\n        """\n        results = {}\n\n        for mode in modes:\n            mode_results = []\n\n            for task in task_list:\n                # Randomly assign task to mode (with balancing)\n                if random.random() < 0.5:\n                    result = self.execute_task_with_mode(task, mode)\n                    mode_results.append(result)\n\n            results[mode.value] = self.analyze_results(mode_results)\n\n        # Select best performing mode\n        best_mode = max(results.keys(), key=lambda k: results[k][\'success_rate\'])\n        self.current_mode = ControlMode(best_mode)\n\n        return results, self.current_mode\n\n    def analyze_results(self, results):\n        """\n        Analyze test results\n        """\n        if not results:\n            return {"success_rate": 0, "avg_time": float(\'inf\'), "safety_score": 0}\n\n        success_count = sum(1 for r in results if r.success)\n        success_rate = success_count / len(results)\n\n        avg_time = np.mean([r.execution_time for r in results if r.success]) if success_count > 0 else float(\'inf\')\n\n        safety_score = np.mean([r.safety_score for r in results])\n\n        return {\n            "success_rate": success_rate,\n            "avg_time": avg_time,\n            "safety_score": safety_score,\n            "total_tasks": len(results)\n        }\n'})}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting-common-deployment-issues",children:"Troubleshooting Common Deployment Issues"}),"\n",(0,i.jsx)(n.h3,{id:"1-actuator-saturation",children:"1. Actuator Saturation"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Simulated actuators may not have the same limitations as real hardware."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Solution"}),": Implement actuator saturation limits and monitoring:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class ActuatorLimiter:\n    def __init__(self):\n        self.torque_limits = {}  # Set based on real hardware specs\n        self.velocity_limits = {}  # Set based on real hardware specs\n\n    def apply_actuator_limits(self, desired_torques, desired_velocities):\n        """\n        Apply hardware-specific actuator limits\n        """\n        limited_torques = np.clip(desired_torques, -self.torque_limits, self.torque_limits)\n        limited_velocities = np.clip(desired_velocities, -self.velocity_limits, self.velocity_limits)\n\n        return limited_torques, limited_velocities\n'})}),"\n",(0,i.jsx)(n.h3,{id:"2-sensor-noise-and-drift",children:"2. Sensor Noise and Drift"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Real sensors have noise, bias, and drift that aren't present in simulation."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Solution"}),": Implement robust filtering and calibration:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class RobustSensorProcessor:\n    def __init__(self):\n        self.filters = {}  # Kalman filters for each sensor type\n        self.bias_estimators = {}  # Online bias estimation\n\n    def process_sensor_data(self, raw_data, sensor_type):\n        """\n        Process sensor data with noise reduction and bias correction\n        """\n        # Apply appropriate filter based on sensor type\n        if sensor_type == \'imu\':\n            filtered_data = self.apply_imu_filter(raw_data)\n        elif sensor_type == \'encoder\':\n            filtered_data = self.apply_encoder_filter(raw_data)\n        else:\n            filtered_data = raw_data\n\n        # Apply bias correction\n        corrected_data = self.apply_bias_correction(filtered_data, sensor_type)\n\n        return corrected_data\n'})}),"\n",(0,i.jsx)(n.h3,{id:"3-model-parameter-mismatch",children:"3. Model Parameter Mismatch"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Physical robot parameters differ from simulation model."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Solution"}),": Implement online parameter adaptation:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class ParameterAdapter:\n    def __init__(self, initial_params):\n        self.current_params = initial_params.copy()\n        self.param_history = []\n\n    def adapt_parameters_online(self, observed_behavior, expected_behavior):\n        """\n        Adapt model parameters based on observed vs expected behavior\n        """\n        error = observed_behavior - expected_behavior\n\n        # Use gradient-based adaptation\n        learning_rate = 0.01\n        param_gradients = self.compute_param_gradients(error)\n\n        for param_name, gradient in param_gradients.items():\n            self.current_params[param_name] -= learning_rate * gradient\n\n        self.param_history.append(self.current_params.copy())\n\n        return self.current_params\n'})}),"\n",(0,i.jsx)(n.p,{children:"Successfully deploying humanoid control systems from simulation to reality requires careful attention to calibration, latency, safety, and the many differences between virtual and physical environments. By implementing robust monitoring, safety protocols, and adaptive systems, developers can bridge the reality gap and achieve reliable real-world performance."})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);